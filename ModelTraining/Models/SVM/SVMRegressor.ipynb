{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Value\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../../metrics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = train_test_split(df, train_size=50000, stratify=df['time_to_stop_activity'], random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns = [\n",
    "        \"user\", \n",
    "        'project', \n",
    "        'current_month', \n",
    "        'turnover_num',\n",
    "        'turnover',\n",
    "        'betweenness_centrality_12_intercept',\n",
    "        'betweenness_centrality_12_slope', \n",
    "        'betweenness_centrality_12_std_dev',\n",
    "        'betweenness_centrality_3_intercept', \n",
    "        'betweenness_centrality_3_slope',\n",
    "        'betweenness_centrality_3_std_dev',\n",
    "        'betweenness_centrality_6_intercept', \n",
    "        'betweenness_centrality_6_slope',\n",
    "        'betweenness_centrality_6_std_dev',\n",
    "        'betweenness_centrality_9_intercept', \n",
    "        'betweenness_centrality_9_slope',\n",
    "        'betweenness_centrality_9_std_dev'\n",
    "    ], axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(np.float64)\n",
    "df = df.replace([np.inf], np.nan)\n",
    "\n",
    "for column in df.columns:\n",
    "    max_value = df[column].max(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)\n",
    "\n",
    "df = df.replace([-np.inf], np.nan)\n",
    "\n",
    "for column in df.columns:\n",
    "    max_value = df[column].min(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    max_value = df[column].max(skipna=True) \n",
    "    df[column] = df[column].fillna(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean') \n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = ['time_to_stop_activity'], axis = 1).values\n",
    "y = df['time_to_stop_activity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size = 0.3, \n",
    "    random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, X_train, Y_train, X_test, Y_test):\n",
    "    svr = SVR(kernel='rbf', C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    print(f'{regularization} - {tolerance} finished')\n",
    "    \n",
    "    return {\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = [\n",
    "    (regularization, tolerance) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>13.146077</td>\n",
       "      <td>13.147209</td>\n",
       "      <td>13.142060</td>\n",
       "      <td>13.142094</td>\n",
       "      <td>13.154305</td>\n",
       "      <td>13.206518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>11.807991</td>\n",
       "      <td>11.813036</td>\n",
       "      <td>11.814492</td>\n",
       "      <td>11.833609</td>\n",
       "      <td>11.937170</td>\n",
       "      <td>11.915788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>10.688782</td>\n",
       "      <td>10.705611</td>\n",
       "      <td>10.730526</td>\n",
       "      <td>10.795428</td>\n",
       "      <td>10.859262</td>\n",
       "      <td>10.772401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>9.771922</td>\n",
       "      <td>9.721574</td>\n",
       "      <td>9.694777</td>\n",
       "      <td>9.671482</td>\n",
       "      <td>9.630051</td>\n",
       "      <td>9.535971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>9.320553</td>\n",
       "      <td>9.313347</td>\n",
       "      <td>9.291506</td>\n",
       "      <td>9.248775</td>\n",
       "      <td>9.108106</td>\n",
       "      <td>8.918613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>10.529562</td>\n",
       "      <td>10.511055</td>\n",
       "      <td>10.499839</td>\n",
       "      <td>10.495498</td>\n",
       "      <td>10.647729</td>\n",
       "      <td>10.762351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance            0.01       0.05       0.10       0.20       0.50  \\\n",
       "regularization                                                          \n",
       "0.1             13.146077  13.147209  13.142060  13.142094  13.154305   \n",
       "1.0             11.807991  11.813036  11.814492  11.833609  11.937170   \n",
       "10.0            10.688782  10.705611  10.730526  10.795428  10.859262   \n",
       "100.0            9.771922   9.721574   9.694777   9.671482   9.630051   \n",
       "1000.0           9.320553   9.313347   9.291506   9.248775   9.108106   \n",
       "10000.0         10.529562  10.511055  10.499839  10.495498  10.647729   \n",
       "\n",
       "tolerance            1.00  \n",
       "regularization             \n",
       "0.1             13.206518  \n",
       "1.0             11.915788  \n",
       "10.0            10.772401  \n",
       "100.0            9.535971  \n",
       "1000.0           8.918613  \n",
       "10000.0         10.762351  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>2.623654</td>\n",
       "      <td>2.624505</td>\n",
       "      <td>2.624955</td>\n",
       "      <td>2.627982</td>\n",
       "      <td>2.647314</td>\n",
       "      <td>2.679873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2.189980</td>\n",
       "      <td>2.189699</td>\n",
       "      <td>2.191166</td>\n",
       "      <td>2.195685</td>\n",
       "      <td>2.221544</td>\n",
       "      <td>2.282168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1.894554</td>\n",
       "      <td>1.895815</td>\n",
       "      <td>1.898407</td>\n",
       "      <td>1.907182</td>\n",
       "      <td>1.944910</td>\n",
       "      <td>2.015112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>1.714912</td>\n",
       "      <td>1.714667</td>\n",
       "      <td>1.716755</td>\n",
       "      <td>1.725192</td>\n",
       "      <td>1.773805</td>\n",
       "      <td>1.866259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>1.611588</td>\n",
       "      <td>1.612362</td>\n",
       "      <td>1.615325</td>\n",
       "      <td>1.624107</td>\n",
       "      <td>1.667121</td>\n",
       "      <td>1.729393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>1.578459</td>\n",
       "      <td>1.577971</td>\n",
       "      <td>1.577915</td>\n",
       "      <td>1.578215</td>\n",
       "      <td>1.590021</td>\n",
       "      <td>1.662353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance           0.01      0.05      0.10      0.20      0.50      1.00\n",
       "regularization                                                            \n",
       "0.1             2.623654  2.624505  2.624955  2.627982  2.647314  2.679873\n",
       "1.0             2.189980  2.189699  2.191166  2.195685  2.221544  2.282168\n",
       "10.0            1.894554  1.895815  1.898407  1.907182  1.944910  2.015112\n",
       "100.0           1.714912  1.714667  1.716755  1.725192  1.773805  1.866259\n",
       "1000.0          1.611588  1.612362  1.615325  1.624107  1.667121  1.729393\n",
       "10000.0         1.578459  1.577971  1.577915  1.578215  1.590021  1.662353"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_absolute_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tolerance</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.245646</td>\n",
       "      <td>0.245581</td>\n",
       "      <td>0.245877</td>\n",
       "      <td>0.245875</td>\n",
       "      <td>0.245174</td>\n",
       "      <td>0.242178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.322429</td>\n",
       "      <td>0.322139</td>\n",
       "      <td>0.322056</td>\n",
       "      <td>0.320959</td>\n",
       "      <td>0.315016</td>\n",
       "      <td>0.316243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.386652</td>\n",
       "      <td>0.385686</td>\n",
       "      <td>0.384256</td>\n",
       "      <td>0.380532</td>\n",
       "      <td>0.376869</td>\n",
       "      <td>0.381853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.439263</td>\n",
       "      <td>0.442153</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>0.445027</td>\n",
       "      <td>0.447404</td>\n",
       "      <td>0.452803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>0.465164</td>\n",
       "      <td>0.465578</td>\n",
       "      <td>0.466831</td>\n",
       "      <td>0.469283</td>\n",
       "      <td>0.477355</td>\n",
       "      <td>0.488228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>0.395788</td>\n",
       "      <td>0.396850</td>\n",
       "      <td>0.397494</td>\n",
       "      <td>0.397743</td>\n",
       "      <td>0.389007</td>\n",
       "      <td>0.382430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tolerance           0.01      0.05      0.10      0.20      0.50      1.00\n",
       "regularization                                                            \n",
       "0.1             0.245646  0.245581  0.245877  0.245875  0.245174  0.242178\n",
       "1.0             0.322429  0.322139  0.322056  0.320959  0.315016  0.316243\n",
       "10.0            0.386652  0.385686  0.384256  0.380532  0.376869  0.381853\n",
       "100.0           0.439263  0.442153  0.443690  0.445027  0.447404  0.452803\n",
       "1000.0          0.465164  0.465578  0.466831  0.469283  0.477355  0.488228\n",
       "10000.0         0.395788  0.396850  0.397494  0.397743  0.389007  0.382430"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='r2_score'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressorBenchmark.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Improvement\n",
    "Once the model has not a good performance, we are looking methods and techniques to improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Kernel Trick**\n",
    "SVM can model non-linear relationships between features by using the kernel trick. The default kernel is rbf (Radial Basis Function), but you can experiment with other kernels like:\n",
    "\n",
    "- Linear Kernel: If your data is linearly separable, the linear kernel might be the best choice.\n",
    "- Polynomial Kernel: Captures polynomial relationships between data points. You can control the degree of the polynomial to fit higher-order relationships.\n",
    "- Sigmoid Kernel: Similar to a neural network activation function, this kernel maps data into a hyperbolic tangent space.\n",
    "\n",
    "Action: Try different kernels and see which works best for your data. For non-linear data, rbf is usually a good default, but for linear data, a linear kernel might perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, kernel, X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    svr = SVR(kernel=kernel, C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'kernel': kernel,\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }\n",
    "\n",
    "param_combinations = [\n",
    "    (regularization, tolerance, kernel) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "    for kernel in ['rbf', 'linear', 'poly']\n",
    "]\n",
    "\n",
    "total_tasks = len(param_combinations)\n",
    "\n",
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, kernel, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol, kernel in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressor_KernelTrick_Benchmark.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'rbf']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'linear']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.kernel == 'poly']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Feature Scaling**\n",
    "SVM is sensitive to the scale of the features. Features with larger numerical ranges dominate the decision boundary, so proper scaling is essential. You are already using StandardScaler, but you can also try:\n",
    "\n",
    "- MinMaxScaler: Rescales features into a range, typically [0, 1]. This might work better if your features have different scales.\n",
    "- RobustScaler: This is more robust to outliers because it scales the data based on the median and the interquartile range instead of the mean and standard deviation.\n",
    "\n",
    "Action: Experiment with different scalers and check how each affects the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size = 0.3, \n",
    "    random_state = 11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_svr(regularization, tolerance, scaler, X_train, Y_train, X_test, Y_test):\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    svr = SVR(kernel='rbf', C=regularization, epsilon=tolerance)\n",
    "    svr.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'scaler': type(scaler).__name__,\n",
    "        'regularization': regularization, \n",
    "        'tolerance': tolerance, \n",
    "        'mean_squared_error': mse,\n",
    "        'mean_absolute_error': mae,\n",
    "        'r2_score': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_combinations = [\n",
    "    (regularization, tolerance, scaler) \n",
    "    for regularization in [0.1, 1, 10, 100, 1000, 10000]\n",
    "    for tolerance in [0.01, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "    for scaler in [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = Parallel(n_jobs=6) (\n",
    "    delayed(train_evaluate_svr) (reg, tol, scaler, X_train, Y_train, X_test, Y_test)\n",
    "    for reg, tol, scaler in param_combinations\n",
    ")\n",
    "\n",
    "benchmark_df = pd.DataFrame(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_excel('SVMRegressor_FeatureScaler_Benchmark.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'StandardScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'RobustScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df\\\n",
    "    [benchmark_df.scaler == 'MinMaxScaler']\\\n",
    "    .pivot(\n",
    "        index='regularization', \n",
    "        columns='tolerance', \n",
    "        values='mean_squared_error'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Outliers\n",
    "SVM is highly sensitive to outliers, as they can significantly influence the decision boundary and margins. Outliers can distort the hyperplane, leading to poor generalization.\n",
    "\n",
    "- Outlier Detection: Before training the model, perform outlier detection (e.g., using Z-scores, IQR, or visualizations like box plots) and remove or adjust them.\n",
    "- Adjust Epsilon: If your model has many outliers, you may want to increase epsilon to create a wider margin and minimize the effect of outliers.\n",
    "\n",
    "Action: Identify and handle outliers by removing or transforming them to see if performance improves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
