{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.stats import linregress\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [\n",
    "    #'rdatatable_datatable',\n",
    "    #'facebook_react',\n",
    "    'freecad_freecad'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = list()\n",
    "issues_comments = list()\n",
    "pull_requests = list()\n",
    "pull_request_comments = list()\n",
    "\n",
    "for file in projects:\n",
    "    temp_df = pd.read_excel(f'Files/{file}_issues.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    issues.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_issues_comments.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    issues_comments.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_pull_requests.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    pull_requests.append(temp_df)\n",
    "\n",
    "    temp_df = pd.read_excel(f'Files/{file}_pull_request_comments.xlsx')\n",
    "    temp_df['project'] = file\n",
    "    pull_request_comments.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues = pd.concat(issues)\n",
    "df_issues_comments = pd.concat(issues_comments)\n",
    "df_pull_requests = pd.concat(pull_requests)\n",
    "df_pull_requests_comments = pd.concat(pull_request_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues['created_by'] = df_issues['created_by']\\\n",
    "    .str.replace('https://api.github.com/users/', '', regex = False)\n",
    "\n",
    "df_pull_requests['created_by'] = df_pull_requests['created_by']\\\n",
    "    .str.replace('https://api.github.com/users/', '', regex = False)\n",
    "\n",
    "df_issues_comments['created_by'] = df_issues_comments['created_by']\\\n",
    "    .str.extract(r'login=\"([^\"]+)\"')\n",
    "\n",
    "df_pull_requests_comments['created_by'] = df_pull_requests_comments['created_by']\\\n",
    "    .str.extract(r'login=\"([^\"]+)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_users = pd.concat([\n",
    "        df_issues[['created_by', 'project']],\n",
    "        df_pull_requests[['created_by', 'project']],\n",
    "        df_issues_comments[['created_by', 'project']],\n",
    "        df_pull_requests_comments[['created_by', 'project']]\n",
    "    ])\\\n",
    "    .drop_duplicates()\\\n",
    "    .reset_index()\\\n",
    "    [['created_by', 'project']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_40368/2069917712.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pr_reviewers_by_month['created_at'] = pd.to_datetime(pr_reviewers_by_month['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "pr_reviewers_by_month = df_pull_requests_comments[['created_by', 'created_at', 'pull_request_id', 'project']]\n",
    "pr_reviewers_by_month['created_at'] = pd.to_datetime(pr_reviewers_by_month['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.drop_duplicates()\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "pr_reviewers_by_month = pr_reviewers_by_month.rename(columns={'pull_request_id': 'number_of_revisions'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_40368/1794930000.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  issues_commented['created_at'] = pd.to_datetime(issues_commented['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "issues_commented = df_issues_comments[['created_by', 'created_at', 'issue_id', 'project']]\n",
    "issues_commented['created_at'] = pd.to_datetime(issues_commented['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "issues_commented = issues_commented.drop_duplicates()\n",
    "issues_commented = issues_commented.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "issues_commented = issues_commented.rename(columns={'issue_id': 'number_of_comments_issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_40368/2771644957.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  issues_created['created_at'] = pd.to_datetime(issues_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "issues_created = df_issues[['created_by', 'created_at', 'id', 'project']]\n",
    "issues_created['created_at'] = pd.to_datetime(issues_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "issues_created = issues_created.drop_duplicates()\n",
    "issues_created = issues_created.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "issues_created = issues_created.rename(columns={'id': 'number_of_issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_40368/605893098.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pull_request_created['created_at'] = pd.to_datetime(pull_request_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n"
     ]
    }
   ],
   "source": [
    "pull_request_created = df_pull_requests[['created_by', 'created_at', 'id', 'project']]\n",
    "pull_request_created['created_at'] = pd.to_datetime(pull_request_created['created_at'], errors='coerce').dt.strftime('%Y-%m')\n",
    "pull_request_created = pull_request_created.drop_duplicates()\n",
    "pull_request_created = pull_request_created.groupby(['created_at', 'created_by', 'project']).count().reset_index()\n",
    "pull_request_created = pull_request_created.rename(columns={'id': 'number_of_pr'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issues_interaction = pd.concat([\n",
    "        df_issues_comments[['issue_id', 'created_by', 'created_at', 'project']],\n",
    "        df_issues[['id', 'created_by', 'created_at', 'project']].rename(columns = {'id': 'issue_id'})\n",
    "    ], ignore_index=True)\n",
    "\n",
    "df_pr_interaction = pd.concat(\n",
    "    [\n",
    "        df_pull_requests_comments[['pull_request_id', 'created_by', 'created_at', 'project']],\n",
    "        df_pull_requests[['id', 'created_by', 'created_at', 'project']].rename(columns = {'id': 'pull_request_id'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_issues_interaction['object'] = 'Issue'\n",
    "df_pr_interaction['object'] = 'PullRequest'\n",
    "\n",
    "df_interaction = pd.concat([\n",
    "        df_pr_interaction.rename(columns = {'pull_request_id': 'id'}),\n",
    "        df_issues_interaction.rename(columns = {'issue_id': 'id'})\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df_interaction['created_at'] = pd.to_datetime(df_interaction['created_at']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interaction = df_interaction\\\n",
    "    .sort_values(by = ['object', 'created_at'])\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "interactions = []\n",
    "interaction_points = defaultdict(int)\n",
    "\n",
    "for project in df_interaction['project'].unique():\n",
    "    temp_df = df_interaction[df_interaction['project'] == project]\n",
    "    \n",
    "    for obj in temp_df['object'].unique():\n",
    "        obj_df = temp_df[temp_df['object'] == obj]\n",
    "\n",
    "        for page in obj_df['id'].unique():\n",
    "            page_df = obj_df[obj_df['id'] == page]\n",
    "            \n",
    "            previous_users = set()\n",
    "\n",
    "            for _, row in page_df.iterrows():\n",
    "                current_user = row['created_by']\n",
    "                created_at = row['created_at']\n",
    "                \n",
    "                for user in previous_users:\n",
    "                    interaction_points[(current_user, user, created_at, project)] += 1\n",
    "                \n",
    "                previous_users.add(current_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.DataFrame(\n",
    "    [(dev_a, dev_b, created_at, project, points) for (dev_a, dev_b, created_at, project), points in interaction_points.items()],\n",
    "    columns=['Developer_A', 'Interacted_With', 'Created_At', 'Project', 'Points']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = interactions_df\\\n",
    "    .groupby(['Developer_A', 'Interacted_With', 'Created_At', 'Project'])\\\n",
    "    .agg(Total_Interactions_A_to_B=('Points', 'sum'))\\\n",
    "    .reset_index()\n",
    "\n",
    "reverse_interactions = interactions_df\\\n",
    "    .rename(columns={'Developer_A': 'Interacted_With', 'Interacted_With': 'Developer_A'})\\\n",
    "    .groupby(['Developer_A', 'Interacted_With', 'Created_At', 'Project'])\\\n",
    "    .agg(Total_Interactions_B_to_A = ('Points', 'sum'))\\\n",
    "    .reset_index()\n",
    "\n",
    "df = pd.merge(\n",
    "        aggregated, \n",
    "        reverse_interactions, \n",
    "        on = ['Developer_A', 'Interacted_With', 'Created_At', 'Project'], \n",
    "        how = 'outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "df['Relationship_Strength'] = df[['Total_Interactions_A_to_B', 'Total_Interactions_B_to_A']].min(axis=1)\n",
    "df = df[df['Developer_A'] != df['Interacted_With']]\n",
    "df = df.rename(columns={'Interacted_With': 'Developer_B', 'Created_At': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_metrics = []\n",
    "\n",
    "for project in df['Project'].drop_duplicates():\n",
    "    \n",
    "    temp_df = df[df['Project'] == project]\n",
    "    \n",
    "    for month, month_df in temp_df.groupby(temp_df['Date']):\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        \n",
    "        for _, row in month_df.iterrows():\n",
    "            G.add_edge(\n",
    "                row['Developer_A'], \n",
    "                row['Developer_B'], \n",
    "                weight=row['Relationship_Strength']\n",
    "            )\n",
    "        \n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        betweenness_centrality = nx.betweenness_centrality(G, weight='weight')\n",
    "        closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "        for user in G.nodes():\n",
    "            user_edges = list(G.edges(user, data=True))\n",
    "            num_relationships = len(user_edges)\n",
    "            \n",
    "            avg_strength = (\n",
    "                sum(edge_data['weight'] for _, _, edge_data in user_edges) / num_relationships\n",
    "                if num_relationships > 0 else 0\n",
    "            )\n",
    "\n",
    "            monthly_metrics.append({\n",
    "                'user': user,\n",
    "                'month': month,\n",
    "                'degree_centrality': degree_centrality.get(user, 0),\n",
    "                'betweenness_centrality': betweenness_centrality.get(user, 0),\n",
    "                'closeness_centrality': closeness_centrality.get(user, 0),\n",
    "                'num_relationships': num_relationships,\n",
    "                'avg_strength': avg_strength,\n",
    "                'project': project,\n",
    "            })\n",
    "\n",
    "\n",
    "    network_df = pd.DataFrame(monthly_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dim_users\\\n",
    "    .merge(\n",
    "        pr_reviewers_by_month,\n",
    "        on=['created_by', 'project'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        issues_created,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        issues_commented,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .merge(\n",
    "        pull_request_created,\n",
    "        on=['created_by', 'project', 'created_at'], \n",
    "        how='outer'\n",
    "    )\\\n",
    "    .rename(\n",
    "        columns = {\n",
    "            'created_by': 'user',\n",
    "            'created_at': 'month'\n",
    "        }\n",
    "    )\\\n",
    "    .merge(\n",
    "        network_df,\n",
    "        on=['user', 'month', 'project']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = [\n",
    "    'number_of_revisions',\n",
    "    'number_of_issues',\n",
    "    'number_of_comments_issues',\n",
    "    'number_of_pr',\n",
    "    'degree_centrality',\n",
    "    'betweenness_centrality',\n",
    "    'closeness_centrality',\n",
    "    'num_relationships',\n",
    "    'avg_strength',\n",
    "]\n",
    "\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    group = group.sort_values(by='month', ascending=True) \n",
    "    \n",
    "    for idx, current_month in enumerate(group['month']):\n",
    "    \n",
    "        full_months = pd.date_range(start=current_month, periods=13, freq='MS')\n",
    "        full_months_period = full_months.to_period('M')\n",
    "        \n",
    "        existing_months_period = group['month']\n",
    "        missing_months = full_months_period.difference(existing_months_period)\n",
    "    \n",
    "        if not missing_months.empty:\n",
    "            missing_data = pd.DataFrame({\n",
    "                'user': developer,\n",
    "                'project': project,\n",
    "                'month':  pd.to_datetime(missing_months.start_time).strftime('%Y-%m'),\n",
    "                'number_of_revisions': 0,\n",
    "                'number_of_issues': 0,\n",
    "                'number_of_comments_issues': 0,\n",
    "                'number_of_pr': 0,\n",
    "                'degree_centrality': 0,\n",
    "                'betweenness_centrality': 0,\n",
    "                'closeness_centrality': 0,\n",
    "                'num_relationships': 0,\n",
    "                'avg_strength': 0\n",
    "            })\n",
    "            all_rows.append(missing_data)\n",
    "\n",
    "if all_rows:\n",
    "    missing_months_df = pd.concat(all_rows, ignore_index=True)\n",
    "    df = pd\\\n",
    "        .concat([df, missing_months_df], ignore_index=True)\\\n",
    "        .drop_duplicates(subset=['user', 'project', 'month'])\n",
    "\n",
    "df = df.sort_values(by=['user', 'project', 'month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = []\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    group = group.sort_values(by='month', ascending=False)\n",
    "    group['month'] = pd.to_datetime(group['month'])\n",
    "    group['month_number'] = np.arange(len(group))\n",
    "\n",
    "    for idx, current_month in enumerate(group['month']):\n",
    "        current_month = pd.to_datetime(current_month)\n",
    "        \n",
    "        full_months = pd.date_range(end=current_month, periods=13, freq='MS')\n",
    "        group['month_year'] = group['month'].dt.to_period('M')\n",
    "        full_months_period = full_months.to_period('M')\n",
    "        missing_months = full_months_period.difference(group['month_year'])\n",
    "        \n",
    "        if not missing_months.empty:\n",
    "            missing_data = pd.DataFrame({\n",
    "                'month': missing_months.start_time,\n",
    "                'user': developer,\n",
    "                'project': project,\n",
    "                'month_number': np.arange(len(group), len(group) + len(missing_months)),\n",
    "                'number_of_revisions': 0,\n",
    "                'number_of_issues': 0,\n",
    "                'number_of_comments_issues': 0,\n",
    "                'number_of_pr': 0,\n",
    "                'degree_centrality': 0,\n",
    "                'betweenness_centrality': 0,\n",
    "                'closeness_centrality': 0,\n",
    "                'num_relationships': 0,\n",
    "                'avg_strength': 0\n",
    "            })\n",
    "            group = pd.concat([group, missing_data], ignore_index=True)\n",
    "\n",
    "        for window in [3, 6, 9, 12]:\n",
    "            if len(group) < window:\n",
    "                continue\n",
    "            \n",
    "            window_data = group.tail(window)\n",
    "            x = window_data['month_number']\n",
    "            \n",
    "            for metric in [\n",
    "                'number_of_revisions', \n",
    "                'number_of_issues', \n",
    "                'number_of_comments_issues', \n",
    "                'number_of_pr', \n",
    "                'degree_centrality', \n",
    "                'betweenness_centrality', \n",
    "                'closeness_centrality',\n",
    "                'num_relationships', \n",
    "                'avg_strength'\n",
    "            ]:\n",
    "                y = window_data[metric]\n",
    "                slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "                \n",
    "                predicted_y = slope * x + intercept\n",
    "                residuals = y - predicted_y\n",
    "                std_dev = np.std(residuals)\n",
    "                \n",
    "                result = {\n",
    "                    'user': developer,\n",
    "                    'project': project,\n",
    "                    'current_month': current_month,\n",
    "                    f'{metric}_{window}_slope': slope,\n",
    "                    f'{metric}_{window}_intercept': intercept,\n",
    "                    f'{metric}_{window}_std_dev': std_dev\n",
    "                }\n",
    "                \n",
    "                regression_results.append(result)\n",
    "\n",
    "regression_df = pd.DataFrame(regression_results)\n",
    "\n",
    "regression_df_pivot = regression_df.pivot_table(\n",
    "    index=['user', 'project', 'current_month'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "regression_df_pivot.columns = [f'{col}' for col in regression_df_pivot.columns]\n",
    "regression_df_pivot.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_columns = ['avg_strength_12_intercept', 'avg_strength_12_slope', 'avg_strength_12_std_dev', 'avg_strength_3_intercept', 'avg_strength_3_slope', 'avg_strength_3_std_dev', 'avg_strength_6_intercept', 'avg_strength_6_slope', 'avg_strength_6_std_dev', 'avg_strength_9_intercept', 'avg_strength_9_slope', 'avg_strength_9_std_dev', 'betweenness_centrality_12_intercept', 'betweenness_centrality_12_slope', 'betweenness_centrality_12_std_dev', 'betweenness_centrality_3_intercept', 'betweenness_centrality_3_slope', 'betweenness_centrality_3_std_dev', 'betweenness_centrality_6_intercept', 'betweenness_centrality_6_slope', 'betweenness_centrality_6_std_dev', 'betweenness_centrality_9_intercept', 'betweenness_centrality_9_slope', 'betweenness_centrality_9_std_dev', 'closeness_centrality_12_intercept', 'closeness_centrality_12_slope', 'closeness_centrality_12_std_dev', 'closeness_centrality_3_intercept', 'closeness_centrality_3_slope', 'closeness_centrality_3_std_dev', 'closeness_centrality_6_intercept', 'closeness_centrality_6_slope', 'closeness_centrality_6_std_dev', 'closeness_centrality_9_intercept', 'closeness_centrality_9_slope', 'closeness_centrality_9_std_dev', 'degree_centrality_12_intercept', 'degree_centrality_12_slope', 'degree_centrality_12_std_dev', 'degree_centrality_3_intercept', 'degree_centrality_3_slope', 'degree_centrality_3_std_dev', 'degree_centrality_6_intercept', 'degree_centrality_6_slope', 'degree_centrality_6_std_dev', 'degree_centrality_9_intercept', 'degree_centrality_9_slope', 'degree_centrality_9_std_dev', 'num_relationships_12_intercept', 'num_relationships_12_slope', 'num_relationships_12_std_dev', 'num_relationships_3_intercept', 'num_relationships_3_slope', 'num_relationships_3_std_dev', 'num_relationships_6_intercept', 'num_relationships_6_slope', 'num_relationships_6_std_dev', 'num_relationships_9_intercept', 'num_relationships_9_slope', 'num_relationships_9_std_dev', 'number_of_comments_issues_12_intercept', 'number_of_comments_issues_12_slope', 'number_of_comments_issues_12_std_dev', 'number_of_comments_issues_3_intercept', 'number_of_comments_issues_3_slope', 'number_of_comments_issues_3_std_dev', 'number_of_comments_issues_6_intercept', 'number_of_comments_issues_6_slope', 'number_of_comments_issues_6_std_dev', 'number_of_comments_issues_9_intercept', 'number_of_comments_issues_9_slope', 'number_of_comments_issues_9_std_dev', 'number_of_issues_12_intercept', 'number_of_issues_12_slope', 'number_of_issues_12_std_dev', 'number_of_issues_3_intercept', 'number_of_issues_3_slope', 'number_of_issues_3_std_dev', 'number_of_issues_6_intercept', 'number_of_issues_6_slope', 'number_of_issues_6_std_dev', 'number_of_issues_9_intercept', 'number_of_issues_9_slope', 'number_of_issues_9_std_dev', 'number_of_pr_12_intercept', 'number_of_pr_12_slope', 'number_of_pr_12_std_dev', 'number_of_pr_3_intercept', 'number_of_pr_3_slope', 'number_of_pr_3_std_dev', 'number_of_pr_6_intercept', 'number_of_pr_6_slope', 'number_of_pr_6_std_dev', 'number_of_pr_9_intercept', 'number_of_pr_9_slope', 'number_of_pr_9_std_dev', 'number_of_revisions_12_intercept', 'number_of_revisions_12_slope', 'number_of_revisions_12_std_dev', 'number_of_revisions_3_intercept', 'number_of_revisions_3_slope', 'number_of_revisions_3_std_dev', 'number_of_revisions_6_intercept', 'number_of_revisions_6_slope', 'number_of_revisions_6_std_dev', 'number_of_revisions_9_intercept', 'number_of_revisions_9_slope', 'number_of_revisions_9_std_dev']\n",
    "regression_df_pivot['turnover'] = regression_df_pivot[activity_columns].sum(axis=1) == 0\n",
    "regression_df_pivot['turnover'] = regression_df_pivot['turnover'].apply(lambda x: 'died' if x else 'active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = regression_df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>project</th>\n",
       "      <th>current_month</th>\n",
       "      <th>avg_strength_12_intercept</th>\n",
       "      <th>avg_strength_12_slope</th>\n",
       "      <th>avg_strength_12_std_dev</th>\n",
       "      <th>avg_strength_3_intercept</th>\n",
       "      <th>avg_strength_3_slope</th>\n",
       "      <th>avg_strength_3_std_dev</th>\n",
       "      <th>avg_strength_6_intercept</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_revisions_3_intercept</th>\n",
       "      <th>number_of_revisions_3_slope</th>\n",
       "      <th>number_of_revisions_3_std_dev</th>\n",
       "      <th>number_of_revisions_6_intercept</th>\n",
       "      <th>number_of_revisions_6_slope</th>\n",
       "      <th>number_of_revisions_6_std_dev</th>\n",
       "      <th>number_of_revisions_9_intercept</th>\n",
       "      <th>number_of_revisions_9_slope</th>\n",
       "      <th>number_of_revisions_9_std_dev</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user, project, current_month, avg_strength_12_intercept, avg_strength_12_slope, avg_strength_12_std_dev, avg_strength_3_intercept, avg_strength_3_slope, avg_strength_3_std_dev, avg_strength_6_intercept, avg_strength_6_slope, avg_strength_6_std_dev, avg_strength_9_intercept, avg_strength_9_slope, avg_strength_9_std_dev, betweenness_centrality_12_intercept, betweenness_centrality_12_slope, betweenness_centrality_12_std_dev, betweenness_centrality_3_intercept, betweenness_centrality_3_slope, betweenness_centrality_3_std_dev, betweenness_centrality_6_intercept, betweenness_centrality_6_slope, betweenness_centrality_6_std_dev, betweenness_centrality_9_intercept, betweenness_centrality_9_slope, betweenness_centrality_9_std_dev, closeness_centrality_12_intercept, closeness_centrality_12_slope, closeness_centrality_12_std_dev, closeness_centrality_3_intercept, closeness_centrality_3_slope, closeness_centrality_3_std_dev, closeness_centrality_6_intercept, closeness_centrality_6_slope, closeness_centrality_6_std_dev, closeness_centrality_9_intercept, closeness_centrality_9_slope, closeness_centrality_9_std_dev, degree_centrality_12_intercept, degree_centrality_12_slope, degree_centrality_12_std_dev, degree_centrality_3_intercept, degree_centrality_3_slope, degree_centrality_3_std_dev, degree_centrality_6_intercept, degree_centrality_6_slope, degree_centrality_6_std_dev, degree_centrality_9_intercept, degree_centrality_9_slope, degree_centrality_9_std_dev, num_relationships_12_intercept, num_relationships_12_slope, num_relationships_12_std_dev, num_relationships_3_intercept, num_relationships_3_slope, num_relationships_3_std_dev, num_relationships_6_intercept, num_relationships_6_slope, num_relationships_6_std_dev, num_relationships_9_intercept, num_relationships_9_slope, num_relationships_9_std_dev, number_of_comments_issues_12_intercept, number_of_comments_issues_12_slope, number_of_comments_issues_12_std_dev, number_of_comments_issues_3_intercept, number_of_comments_issues_3_slope, number_of_comments_issues_3_std_dev, number_of_comments_issues_6_intercept, number_of_comments_issues_6_slope, number_of_comments_issues_6_std_dev, number_of_comments_issues_9_intercept, number_of_comments_issues_9_slope, number_of_comments_issues_9_std_dev, number_of_issues_12_intercept, number_of_issues_12_slope, number_of_issues_12_std_dev, number_of_issues_3_intercept, number_of_issues_3_slope, number_of_issues_3_std_dev, number_of_issues_6_intercept, number_of_issues_6_slope, number_of_issues_6_std_dev, number_of_issues_9_intercept, number_of_issues_9_slope, number_of_issues_9_std_dev, number_of_pr_12_intercept, number_of_pr_12_slope, number_of_pr_12_std_dev, number_of_pr_3_intercept, number_of_pr_3_slope, number_of_pr_3_std_dev, number_of_pr_6_intercept, number_of_pr_6_slope, number_of_pr_6_std_dev, number_of_pr_9_intercept, number_of_pr_9_slope, number_of_pr_9_std_dev, number_of_revisions_12_intercept, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 112 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.user == 'minemR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['user', 'project', 'current_month']).reset_index(drop=True)\n",
    "cleaned_data = []\n",
    "\n",
    "for (developer, project), group in df.groupby(['user', 'project']):\n",
    "    death_months = group[group['turnover'] == 'died']['current_month']\n",
    "    \n",
    "    if not death_months.empty:\n",
    "        for death_month in death_months:\n",
    "            pre_death_range = pd.date_range(\n",
    "                end = death_month - pd.DateOffset(months=1),\n",
    "                periods = 11,\n",
    "                freq='MS'\n",
    "            )\n",
    "            \n",
    "            last_month = death_month - pd.DateOffset(months=12)\n",
    "\n",
    "            for _, row in group.iterrows():\n",
    "                if row['current_month'] in pre_death_range:\n",
    "                    row['turnover'] = 'pre-death'\n",
    "                \n",
    "                elif row['current_month'] == last_month:\n",
    "                    row['turnover'] = 'last_month'\n",
    "\n",
    "                cleaned_data.append(row)\n",
    "    else:\n",
    "        cleaned_data.extend(group.to_dict('records'))\n",
    "\n",
    "df_cleaned = pd.DataFrame(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/3ypglz8x6bx6_n9y6760l6n9h4gtsy/T/ipykernel_40368/967631428.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_cleaned = df_cleaned.groupby(['user', 'project']).apply(lambda x: x.iloc[1:]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.sort_values(by=['user', 'project', 'current_month']).reset_index(drop=True)\n",
    "df_cleaned = df_cleaned.groupby(['user', 'project']).apply(lambda x: x.iloc[1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>project</th>\n",
       "      <th>current_month</th>\n",
       "      <th>avg_strength_12_intercept</th>\n",
       "      <th>avg_strength_12_slope</th>\n",
       "      <th>avg_strength_12_std_dev</th>\n",
       "      <th>avg_strength_3_intercept</th>\n",
       "      <th>avg_strength_3_slope</th>\n",
       "      <th>avg_strength_3_std_dev</th>\n",
       "      <th>avg_strength_6_intercept</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_revisions_3_intercept</th>\n",
       "      <th>number_of_revisions_3_slope</th>\n",
       "      <th>number_of_revisions_3_std_dev</th>\n",
       "      <th>number_of_revisions_6_intercept</th>\n",
       "      <th>number_of_revisions_6_slope</th>\n",
       "      <th>number_of_revisions_6_std_dev</th>\n",
       "      <th>number_of_revisions_9_intercept</th>\n",
       "      <th>number_of_revisions_9_slope</th>\n",
       "      <th>number_of_revisions_9_std_dev</th>\n",
       "      <th>turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21311</th>\n",
       "      <td>VinceBa</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21315</th>\n",
       "      <td>VinceBa</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21320</th>\n",
       "      <td>VinceBa</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21319</th>\n",
       "      <td>VinceBa</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21318</th>\n",
       "      <td>VinceBa</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48483</th>\n",
       "      <td>j-wiedemann</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48482</th>\n",
       "      <td>j-wiedemann</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81504</th>\n",
       "      <td>yorikvanhavre</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81503</th>\n",
       "      <td>yorikvanhavre</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48481</th>\n",
       "      <td>j-wiedemann</td>\n",
       "      <td>freecad_freecad</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14630 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user          project current_month  \\\n",
       "21311        VinceBa  freecad_freecad    2024-11-01   \n",
       "21315        VinceBa  freecad_freecad    2024-11-01   \n",
       "21320        VinceBa  freecad_freecad    2024-11-01   \n",
       "21319        VinceBa  freecad_freecad    2024-11-01   \n",
       "21318        VinceBa  freecad_freecad    2024-11-01   \n",
       "...              ...              ...           ...   \n",
       "48483    j-wiedemann  freecad_freecad    2015-10-01   \n",
       "48482    j-wiedemann  freecad_freecad    2015-10-01   \n",
       "81504  yorikvanhavre  freecad_freecad    2015-10-01   \n",
       "81503  yorikvanhavre  freecad_freecad    2015-10-01   \n",
       "48481    j-wiedemann  freecad_freecad    2015-09-01   \n",
       "\n",
       "       avg_strength_12_intercept  avg_strength_12_slope  \\\n",
       "21311                        0.0                    0.0   \n",
       "21315                        0.0                    0.0   \n",
       "21320                        0.0                    0.0   \n",
       "21319                        0.0                    0.0   \n",
       "21318                        0.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "48483                        0.0                    0.0   \n",
       "48482                        0.0                    0.0   \n",
       "81504                        0.0                    0.0   \n",
       "81503                        0.0                    0.0   \n",
       "48481                        0.0                    0.0   \n",
       "\n",
       "       avg_strength_12_std_dev  avg_strength_3_intercept  \\\n",
       "21311                      0.0                       0.0   \n",
       "21315                      0.0                       0.0   \n",
       "21320                      0.0                       0.0   \n",
       "21319                      0.0                       0.0   \n",
       "21318                      0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "48483                      0.0                       0.0   \n",
       "48482                      0.0                       0.0   \n",
       "81504                      0.0                       0.0   \n",
       "81503                      0.0                       0.0   \n",
       "48481                      0.0                       0.0   \n",
       "\n",
       "       avg_strength_3_slope  avg_strength_3_std_dev  avg_strength_6_intercept  \\\n",
       "21311                   0.0                     0.0                       0.0   \n",
       "21315                   0.0                     0.0                       0.0   \n",
       "21320                   0.0                     0.0                       0.0   \n",
       "21319                   0.0                     0.0                       0.0   \n",
       "21318                   0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "48483                   0.0                     0.0                       0.0   \n",
       "48482                   0.0                     0.0                       0.0   \n",
       "81504                   0.0                     0.0                       0.0   \n",
       "81503                   0.0                     0.0                       0.0   \n",
       "48481                   0.0                     0.0                       0.0   \n",
       "\n",
       "       ...  number_of_revisions_3_intercept  number_of_revisions_3_slope  \\\n",
       "21311  ...                              0.0                          0.0   \n",
       "21315  ...                              0.0                          0.0   \n",
       "21320  ...                              0.0                          0.0   \n",
       "21319  ...                              0.0                          0.0   \n",
       "21318  ...                              0.0                          0.0   \n",
       "...    ...                              ...                          ...   \n",
       "48483  ...                              0.0                          0.0   \n",
       "48482  ...                              0.0                          0.0   \n",
       "81504  ...                              0.0                          0.0   \n",
       "81503  ...                              0.0                          0.0   \n",
       "48481  ...                              0.0                          0.0   \n",
       "\n",
       "       number_of_revisions_3_std_dev  number_of_revisions_6_intercept  \\\n",
       "21311                            0.0                              0.0   \n",
       "21315                            0.0                              0.0   \n",
       "21320                            0.0                              0.0   \n",
       "21319                            0.0                              0.0   \n",
       "21318                            0.0                              0.0   \n",
       "...                              ...                              ...   \n",
       "48483                            0.0                              0.0   \n",
       "48482                            0.0                              0.0   \n",
       "81504                            0.0                              0.0   \n",
       "81503                            0.0                              0.0   \n",
       "48481                            0.0                              0.0   \n",
       "\n",
       "       number_of_revisions_6_slope  number_of_revisions_6_std_dev  \\\n",
       "21311                          0.0                            0.0   \n",
       "21315                          0.0                            0.0   \n",
       "21320                          0.0                            0.0   \n",
       "21319                          0.0                            0.0   \n",
       "21318                          0.0                            0.0   \n",
       "...                            ...                            ...   \n",
       "48483                          0.0                            0.0   \n",
       "48482                          0.0                            0.0   \n",
       "81504                          0.0                            0.0   \n",
       "81503                          0.0                            0.0   \n",
       "48481                          0.0                            0.0   \n",
       "\n",
       "       number_of_revisions_9_intercept  number_of_revisions_9_slope  \\\n",
       "21311                              0.0                          0.0   \n",
       "21315                              0.0                          0.0   \n",
       "21320                              0.0                          0.0   \n",
       "21319                              0.0                          0.0   \n",
       "21318                              0.0                          0.0   \n",
       "...                                ...                          ...   \n",
       "48483                              0.0                          0.0   \n",
       "48482                              0.0                          0.0   \n",
       "81504                              0.0                          0.0   \n",
       "81503                              0.0                          0.0   \n",
       "48481                              0.0                          0.0   \n",
       "\n",
       "       number_of_revisions_9_std_dev  turnover  \n",
       "21311                            0.0      died  \n",
       "21315                            0.0      died  \n",
       "21320                            0.0      died  \n",
       "21319                            0.0      died  \n",
       "21318                            0.0      died  \n",
       "...                              ...       ...  \n",
       "48483                            0.0      died  \n",
       "48482                            0.0      died  \n",
       "81504                            0.0      died  \n",
       "81503                            0.0      died  \n",
       "48481                            0.0      died  \n",
       "\n",
       "[14630 rows x 112 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned[df_cleaned.turnover == 'died'].sort_values(by = 'current_month', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
